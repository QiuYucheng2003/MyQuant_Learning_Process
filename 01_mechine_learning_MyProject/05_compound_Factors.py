import pandas as pd
import numpy as np
import xgboost as xgb
from tqdm import tqdm
import warnings
import matplotlib.pyplot as plt
import os

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

# ================= é…ç½®å‚æ•° =================
INPUT_FILE = 'sz100_Final_Selected_Factors.csv'
OUTPUT_FILE = 'sz100_Final_Composite_Score.csv'

# æ ¸å¿ƒå› å­åˆ—è¡¨ (Alpha_2 æœ€å¼º)
FACTOR_COLS = ['GP_ALPHA_2_EMA_10', 'GP_ALPHA_1_EMA_3', 'GP_ALPHA_3_EMA_10']

# é¢„æµ‹ç›®æ ‡
TARGET_LABEL = 'RET_FWD_5_RANK'

# æ»šåŠ¨è®­ç»ƒå‚æ•° (ç”¨äº XGBoost)
TRAIN_WINDOW = 242  # çº¦1å¹´
TEST_WINDOW = 20  # çº¦1ä¸ªæœˆ

# Plan B: XGBoost å‚æ•° (è¿›ä¸€æ­¥ç®€åŒ–ä»¥é˜²è¿‡æ‹Ÿåˆ)
XGB_PARAMS = {
    'objective': 'reg:squarederror',
    'n_estimators': 20,  # å†æ¬¡å‡å°‘æ ‘çš„æ•°é‡
    'max_depth': 2,  # æç®€æ ‘æ·± (ç±»ä¼¼çº¿æ€§å›å½’åŠ ä¸€ç‚¹ç‚¹éçº¿æ€§)
    'learning_rate': 0.1,
    'subsample': 0.7,
    'colsample_bytree': 0.5,  # æ¯æ¬¡åªçœ‹ä¸€åŠç‰¹å¾ï¼Œå¼ºåˆ¶æ¨¡å‹åˆ©ç”¨å¼±å› å­
    'n_jobs': -1,
    'random_state': 42
}


# ================= æ–¹æ³•ä¸€ï¼šç®€å•ç­‰æƒåˆæˆ (Plan A) =================
# é€»è¾‘ï¼šæ ‡å‡†åŒ– -> å¹³å‡ -> å˜å·
# è¿™æ˜¯æœ€ç¨³å¥çš„åŸºå‡†ï¼Œå¾€å¾€æ¯”å¤æ‚çš„ ML æ¨¡å‹æ›´æœ‰æ•ˆ

def calc_simple_composite(df, factors):
    print(f"\n[Plan A] æ­£åœ¨è®¡ç®—ç®€å•ç­‰æƒåˆæˆ (Factors={len(factors)})...")

    # ä¸´æ—¶ DataFrame
    temp_df = df[['date', 'code'] + factors].copy()

    # å®šä¹‰æ¯æ—¥æ ‡å‡†åŒ–å‡½æ•°
    def process_day(group):
        score_sum = 0
        valid_count = 0

        for col in factors:
            # å¼ºåˆ¶è½¬æ•°å€¼
            series = pd.to_numeric(group[col], errors='coerce')

            # æˆªé¢ Z-Score æ ‡å‡†åŒ– (å…³é”®ï¼)
            if series.std() != 0:
                series = (series - series.mean()) / series.std()
            else:
                series = 0

            # ç´¯åŠ  (æ³¨æ„ï¼šå¦‚æœå› å­ IC æ˜¯è´Ÿçš„ï¼Œè¿™é‡Œå…ˆç´¯åŠ ï¼Œæœ€åç»Ÿä¸€å˜å·)
            # å‡è®¾æ‰€æœ‰å› å­æ–¹å‘ä¸€è‡´ï¼ˆéƒ½æ˜¯è´Ÿå‘å› å­ï¼‰
            score_sum += series

        # è®¡ç®—å¹³å‡å¹¶å–å (å› ä¸ºåŸå› å­ IC å‡çº¦ä¸º -0.05ï¼Œå–åå Score è¶Šå¤§è¶Šå¥½)
        return -1 * score_sum / len(factors)

    # Apply (å› è®¡ç®—é‡å°ï¼Œç›´æ¥ groupby apply é—®é¢˜ä¸å¤§ï¼Œæˆ–è€…ç”¨ transform åŠ é€Ÿ)
    # ä¸ºäº†ç¨³å¥ï¼Œä½¿ç”¨ transform é€åˆ—å¤„ç†å†ç›¸åŠ ä¼šæ›´å¿«

    # å¿«é€Ÿå‘é‡åŒ–å®ç°ï¼š
    final_score = pd.Series(0.0, index=df.index)

    # æŒ‰å¤©åˆ†ç»„è®¡ç®—æ¯ä¸ªå› å­çš„ Z-Score å¹¶ç´¯åŠ 
    for col in tqdm(factors, desc="Standardizing"):
        # è½¬æ¢
        vals = pd.to_numeric(df[col], errors='coerce').fillna(0)

        # è®¡ç®—æ¯æ—¥ Mean/Std
        daily_mean = vals.groupby(df['date']).transform('mean')
        daily_std = vals.groupby(df['date']).transform('std').replace(0, 1)  # é˜²æ­¢é™¤0

        # Z-Score
        z_score = (vals - daily_mean) / daily_std

        # ç´¯åŠ 
        final_score += z_score

    # å–åå¹¶å¹³å‡
    final_score = -1 * (final_score / len(factors))

    return final_score


# ================= æ–¹æ³•äºŒï¼šXGBoost åŸå§‹å› å­æ»šåŠ¨ (Plan B) =================
# é€»è¾‘ï¼šä¸åšæ­£äº¤åŒ–ï¼Œç›´æ¥å–‚ç»™ XGBï¼Œè®©æ ‘æ¨¡å‹è‡ªå·±å¤„ç†å…±çº¿æ€§

def train_rolling_xgboost_raw(df, feature_cols, target_col):
    print(f"\n[Plan B] æ­£åœ¨è®­ç»ƒ XGBoost (Raw Factors, No Ortho)...")
    unique_dates = df['date'].sort_values().unique()
    total_len = len(unique_dates)

    preds = []
    start_idx = 0

    pbar = tqdm(total=total_len, desc="XGBoost Rolling")

    while start_idx + TRAIN_WINDOW < total_len:
        # åˆ‡ç‰‡
        train_start = unique_dates[start_idx]
        test_start = unique_dates[start_idx + TRAIN_WINDOW]
        test_end_idx = min(start_idx + TRAIN_WINDOW + TEST_WINDOW, total_len)
        test_end = unique_dates[test_end_idx - 1]

        if test_start > test_end: break

        train_mask = (df['date'] >= train_start) & (df['date'] < test_start)
        test_mask = (df['date'] >= test_start) & (df['date'] <= test_end)

        if train_mask.sum() < 50:  # æ ·æœ¬è¿‡å°‘è·³è¿‡
            start_idx += TEST_WINDOW
            pbar.update(TEST_WINDOW)
            continue

        # å‡†å¤‡æ•°æ® (å¼ºåˆ¶è½¬ float)
        X_train = df.loc[train_mask, feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0)
        y_train = df.loc[train_mask, target_col]
        X_test = df.loc[test_mask, feature_cols].apply(pd.to_numeric, errors='coerce').fillna(0)

        # è®­ç»ƒ
        model = xgb.XGBRegressor(**XGB_PARAMS)
        model.fit(X_train, y_train)

        # é¢„æµ‹
        pred_score = model.predict(X_test)

        # è®°å½•
        temp = df.loc[test_mask, ['date', 'code', 'name', 'RET_FWD_5']].copy()
        temp['SCORE_XGB'] = pred_score
        preds.append(temp)

        start_idx += TEST_WINDOW
        pbar.update(TEST_WINDOW)

    pbar.close()
    if not preds: return pd.DataFrame()
    return pd.concat(preds)


# ================= ä¸»ç¨‹åº =================

def evaluate_performance(df, score_col, target_col):
    """è®¡ç®— IC å’Œ ICIR"""
    df_clean = df.dropna(subset=[score_col, target_col])
    if df_clean.empty: return 0, 0, pd.Series()

    daily_ic = df_clean.groupby('date').apply(
        lambda x: x[score_col].corr(x[target_col], method='spearman')
    )
    return daily_ic.mean(), daily_ic.mean() / daily_ic.std(), daily_ic


def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {INPUT_FILE}")
        return

    print(f"è¯»å–å› å­æ–‡ä»¶: {INPUT_FILE}")
    df = pd.read_csv(INPUT_FILE, dtype={'code': str})
    df['date'] = pd.to_datetime(df['date'])
    df = df.sort_values(['date', 'code']).reset_index(drop=True)

    # è¡¥å…¨ Rank
    if TARGET_LABEL not in df.columns:
        print(f"æ­£åœ¨è®¡ç®— {TARGET_LABEL}...")
        df[TARGET_LABEL] = df.groupby('date')['RET_FWD_5'].rank(pct=True, method='first')

    # ------------------------------------------------------
    # æ‰§è¡Œ Plan A: ç®€å•åˆæˆ
    # ------------------------------------------------------
    df['SCORE_SIMPLE'] = calc_simple_composite(df, FACTOR_COLS)

    # ------------------------------------------------------
    # æ‰§è¡Œ Plan B: XGBoost (æ— æ­£äº¤åŒ–)
    # ------------------------------------------------------
    xgb_res = train_rolling_xgboost_raw(df, FACTOR_COLS, TARGET_LABEL)

    # åˆå¹¶ç»“æœ (XGBoost ç»“æœæ¯”åŸæ•°æ®çŸ­ï¼Œå› ä¸ºæœ‰æ»šåŠ¨çª—å£æœŸ)
    # æˆ‘ä»¬ä»¥ left join æ–¹å¼åˆå¹¶åˆ°ä¸»è¡¨
    final_df = df.merge(xgb_res[['date', 'code', 'SCORE_XGB']], on=['date', 'code'], how='left')

    # ------------------------------------------------------
    # æœ€ç»ˆå¤§æ¯”æ­¦ (Evaluation)
    # ------------------------------------------------------
    print("\n" + "=" * 40)
    print("ğŸš€ æœ€ç»ˆåˆæˆæ•ˆæœå¤§æ¯”æ­¦ (Rank IC)")
    print("=" * 40)

    # è¯„ä¼° Simple
    ic_a, icir_a, daily_ic_a = evaluate_performance(final_df, 'SCORE_SIMPLE', 'RET_FWD_5')
    print(f"[Plan A] ç®€å•ç­‰æƒåˆæˆ:")
    print(f"   IC Mean: {ic_a:.4f}")
    print(f"   ICIR   : {icir_a:.4f}")

    # è¯„ä¼° XGBoost
    # æ³¨æ„ï¼šåªè¯„ä¼°æœ‰ XGB é¢„æµ‹å€¼çš„æ—¥æœŸï¼Œä¸ºäº†å…¬å¹³å¯¹æ¯”ï¼ŒSimple ä¹Ÿåº”è¯¥é™åˆ¶åœ¨åŒæ—¶é—´æ®µ
    valid_xgb_mask = final_df['SCORE_XGB'].notna()
    df_compare = final_df[valid_xgb_mask].copy()

    if not df_compare.empty:
        ic_b, icir_b, daily_ic_b = evaluate_performance(df_compare, 'SCORE_XGB', 'RET_FWD_5')
        # é‡æ–°è®¡ç®—è¯¥æ—¶é—´æ®µçš„ Plan A ä»¥ç¤ºå…¬å¹³
        ic_a_period, icir_a_period, daily_ic_a_period = evaluate_performance(df_compare, 'SCORE_SIMPLE', 'RET_FWD_5')

        print(f"\n[Plan B] XGBoost (Raw) - åŒæœŸå¯¹æ¯”:")
        print(f"   IC Mean: {ic_b:.4f}")
        print(f"   ICIR   : {icir_b:.4f}")

        print(f"\n[Plan A] ç®€å•åˆæˆ (Simple) - åŒæœŸå¯¹æ¯”:")
        print(f"   IC Mean: {ic_a_period:.4f}")
        print(f"   ICIR   : {icir_a_period:.4f}")

        # è‡ªåŠ¨é€‰æ‹©èµ¢å®¶
        winner = 'SCORE_SIMPLE' if icir_a_period > icir_b else 'SCORE_XGB'
        print(f"\nğŸ† èƒœå‡ºè€…: {winner}")

        # ç»˜å›¾å¯¹æ¯”
        plt.figure(figsize=(10, 5))
        daily_ic_a_period.cumsum().plot(label=f'Plan A: Simple (ICIR={icir_a_period:.2f})')
        daily_ic_b.cumsum().plot(label=f'Plan B: XGBoost (ICIR={icir_b:.2f})')
        plt.title('Strategy Comparison: Simple vs XGBoost')
        plt.legend()
        plt.grid(True)
        plt.savefig('Strategy_Comparison.png')
        print("å¯¹æ¯”å›¾å·²ä¿å­˜è‡³ Strategy_Comparison.png")

        # å°†èƒœå‡ºè€…çš„åˆ†æ•°ä½œä¸ºæœ€ç»ˆ PRED_SCORE
        final_df['PRED_SCORE'] = final_df[winner]

    else:
        print("\nâš ï¸ XGBoost å°šæœªç”Ÿæˆè¶³å¤Ÿæ•°æ®ï¼Œé»˜è®¤ä½¿ç”¨ Simple Scoreã€‚")
        final_df['PRED_SCORE'] = final_df['SCORE_SIMPLE']

    # ä¿å­˜
    out_cols = ['date', 'code', 'name', 'RET_FWD_5', 'SCORE_SIMPLE', 'SCORE_XGB', 'PRED_SCORE']
    final_df[out_cols].to_csv(OUTPUT_FILE, index=False)
    print(f"\næœ€ç»ˆç»“æœå·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    print(f"å…¶ä¸­ 'PRED_SCORE' åˆ—ä¸ºè‡ªåŠ¨é€‰å‡ºçš„æœ€ä½³åˆæˆå› å­ã€‚")


if __name__ == "__main__":
    main()